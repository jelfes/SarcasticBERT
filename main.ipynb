{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMPwpFKNAl9i"
   },
   "source": [
    "##**Natural Language Processing - A.Y. 2021/2022** \n",
    "#**Course Project - Humor detection in Tweets: baselines vs BERT**\n",
    "Jan Elefes (2040496) , Giovanna Pilot (2062883) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2xCIp7pDrc2"
   },
   "source": [
    "## Introduction and presentation of the Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoKnujPNCNgO"
   },
   "source": [
    "Humor is a complex sociological phenomenon and plays an essential role in human relationships.  It helps soften tense moments, cheers us up, and makes our lives more pleasant and light.\\\n",
    "In machine learning, there is very little work done on humor detection probably due to the complexity of the task. Being able to automatically recognize humor could improve a lot human-centered artificial intelligence systems such as chatbots and virtual assistants.\\\n",
    "Our work aims to tell whether a tweet is sarcastic and to do so we use different versions of BERT comparing them with baseline models such as logistic regression, SVM, random forest and an LSTM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXGEnMCRFuxg"
   },
   "source": [
    "**BERT**\n",
    "\n",
    "BERT is a model designed specifically for NLP tasks and it involves a multi-layer bidirectional transformer encoder.  Unlike other methods such as LSTM which processes a sentence from left to right one word at a time, BERT simultaneously processes all the words in the sentence. Since BERT was introduced in the NLP world, many other versions of it were released such as Multilingual BERT, RoBERTa, BERTweet and many others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r92WxQKeD8XV"
   },
   "source": [
    "### **Dataset**\n",
    "In this work, we use a dataset from the SemEval 2022 composed of 3467 tweets written in English. The dataset lies within a larger project which aims to detect sarcasm both in English and Arabic [source](https://sites.google.com/view/semeval2022-isarcasmeval#h.t53li2ejhrh8). For the English part of the dataset, each tweet is attached with: \n",
    "* a label specifying its sarcastic nature (sarcastic or non-sarcastic), provided by its author;\n",
    "* a rephrase provided by its author that conveys the same message non-sarcastically; \n",
    "* a label specifying the category of ironic speech that it reflects, provided by a linguistic expert.\n",
    "\n",
    "For what concerns our task we only keep the dummy variable which specifies whether the text is sarcastic. The dataset contains 25% of sarcastic tweets and the majority of sarcastic and non-sarcastic tweets are shorter than 30 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sp2Bfh6eGYCl",
    "outputId": "0683651a-dd5e-4380-9e92-981c4c7320be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 5.1 MB/s \n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 51.9 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 54.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 6.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-pretrained-bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 5.1 MB/s \n",
      "\u001b[?25hCollecting pytorch-nlp\n",
      "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 8.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.11.0+cu113)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.24.22-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 53.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.1.1)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 10.2 MB/s \n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.22\n",
      "  Downloading botocore-1.27.22-py3-none-any.whl (8.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.9 MB 66.1 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 72.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.22->boto3->pytorch-pretrained-bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.22->boto3->pytorch-pretrained-bert) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 74.8 MB/s \n",
      "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.24.22 botocore-1.27.22 jmespath-1.0.1 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting ekphrasis\n",
      "  Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 2.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.21.6)\n",
      "Collecting ujson\n",
      "  Downloading ujson-5.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 3.7 MB/s \n",
      "\u001b[?25hCollecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.64.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.2)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->ekphrasis) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (2022.6.2)\n",
      "Installing collected packages: ujson, ftfy, colorama, ekphrasis\n",
      "Successfully installed colorama-0.4.5 ekphrasis-0.5.4 ftfy-6.1.1 ujson-5.4.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
      "\u001b[K     |████████████████████████████████| 287 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 76.4 MB/s \n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa0f8093350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import AutoModel\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from ekphrasis.classes.segmenter import Segmenter\n",
    "from textblob import TextBlob\n",
    "import contractions\n",
    "import string\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#set the random seed for further operations\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "73nOI6BR9HA1",
    "outputId": "1462d99f-97b7-4fc3-b210-77b2f6628659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tesla T4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# assign gpu to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaEYBXvoGo_T",
    "outputId": "bc6b844f-12ab-4e55-ca5f-fd27b2fe7777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              tweet  sarcastic  \\\n",
      "0           0  The only thing I got from college is a caffein...          1   \n",
      "1           1  I love it when professors draw a big question ...          1   \n",
      "2           2  Remember the hundred emails from companies whe...          1   \n",
      "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
      "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
      "\n",
      "                                            rephrase  sarcasm  irony  satire  \\\n",
      "0  College is really difficult, expensive, tiring...      0.0    1.0     0.0   \n",
      "1  I do not like when professors don’t write out ...      1.0    0.0     0.0   \n",
      "2  I, at the bare minimum, wish companies actuall...      0.0    1.0     0.0   \n",
      "3  Today my pop-pop told me I was not \"forced\" to...      1.0    0.0     0.0   \n",
      "4  I would say Ted Cruz is an asshole and doesn’t...      1.0    0.0     0.0   \n",
      "\n",
      "   understatement  overstatement  rhetorical_question  \n",
      "0             0.0            0.0                  0.0  \n",
      "1             0.0            0.0                  0.0  \n",
      "2             0.0            0.0                  0.0  \n",
      "3             0.0            0.0                  0.0  \n",
      "4             0.0            0.0                  0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 867 entries, 0 to 866\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           867 non-null    int64  \n",
      " 1   tweet                867 non-null    object \n",
      " 2   sarcastic            867 non-null    int64  \n",
      " 3   rephrase             867 non-null    object \n",
      " 4   sarcasm              867 non-null    float64\n",
      " 5   irony                867 non-null    float64\n",
      " 6   satire               867 non-null    float64\n",
      " 7   understatement       867 non-null    float64\n",
      " 8   overstatement        867 non-null    float64\n",
      " 9   rhetorical_question  867 non-null    float64\n",
      "dtypes: float64(6), int64(2), object(2)\n",
      "memory usage: 74.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#we loead the dataset and delate rows with Nan values\n",
    "df = pd.read_csv('train.En.csv')\n",
    "# df=df[['tweet', 'sarcastic']]\n",
    "df=df.dropna()\n",
    "\n",
    "# have a look at some examples\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1018
    },
    "id": "yoLWI4WImckU",
    "outputId": "a71b40ed-9eea-4e1c-f08d-5543318dade8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4589753c-2162-40ab-82bc-8ed9e8860697\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like when professors don’t write out ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>862</td>\n",
       "      <td>yo @claires do yall do hysterectomies?</td>\n",
       "      <td>1</td>\n",
       "      <td>Claires, you should not do full hysterectomies.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>863</td>\n",
       "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
       "      <td>1</td>\n",
       "      <td>A lot of people don't have a wife.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>864</td>\n",
       "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
       "      <td>1</td>\n",
       "      <td>The red cross is always needy.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>865</td>\n",
       "      <td>Update: holding hands with your mom and walkin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Holding hands with your parent while walking a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>866</td>\n",
       "      <td>I might be rubbish at driving, and have a less...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, one of my few cookery skills do...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>867 rows × 10 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4589753c-2162-40ab-82bc-8ed9e8860697')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4589753c-2162-40ab-82bc-8ed9e8860697 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4589753c-2162-40ab-82bc-8ed9e8860697');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0             0  The only thing I got from college is a caffein...          1   \n",
       "1             1  I love it when professors draw a big question ...          1   \n",
       "2             2  Remember the hundred emails from companies whe...          1   \n",
       "3             3  Today my pop-pop told me I was not “forced” to...          1   \n",
       "4             4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "..          ...                                                ...        ...   \n",
       "862         862             yo @claires do yall do hysterectomies?          1   \n",
       "863         863  @JacobWohlReport Do I need to aquire a wife be...          1   \n",
       "864         864  I get a lot of boy who cried wolf vibes from t...          1   \n",
       "865         865  Update: holding hands with your mom and walkin...          1   \n",
       "866         866  I might be rubbish at driving, and have a less...          1   \n",
       "\n",
       "                                              rephrase  sarcasm  irony  \\\n",
       "0    College is really difficult, expensive, tiring...      0.0    1.0   \n",
       "1    I do not like when professors don’t write out ...      1.0    0.0   \n",
       "2    I, at the bare minimum, wish companies actuall...      0.0    1.0   \n",
       "3    Today my pop-pop told me I was not \"forced\" to...      1.0    0.0   \n",
       "4    I would say Ted Cruz is an asshole and doesn’t...      1.0    0.0   \n",
       "..                                                 ...      ...    ...   \n",
       "862   Claires, you should not do full hysterectomies.       1.0    0.0   \n",
       "863                 A lot of people don't have a wife.      1.0    0.0   \n",
       "864                    The red cross is always needy.       0.0    1.0   \n",
       "865  Holding hands with your parent while walking a...      1.0    0.0   \n",
       "866  Unfortunately, one of my few cookery skills do...      1.0    0.0   \n",
       "\n",
       "     satire  understatement  overstatement  rhetorical_question  \n",
       "0       0.0             0.0            0.0                  0.0  \n",
       "1       0.0             0.0            0.0                  0.0  \n",
       "2       0.0             0.0            0.0                  0.0  \n",
       "3       0.0             0.0            0.0                  0.0  \n",
       "4       0.0             0.0            0.0                  0.0  \n",
       "..      ...             ...            ...                  ...  \n",
       "862     0.0             0.0            0.0                  1.0  \n",
       "863     0.0             0.0            0.0                  1.0  \n",
       "864     0.0             0.0            0.0                  0.0  \n",
       "865     0.0             0.0            0.0                  0.0  \n",
       "866     0.0             0.0            0.0                  0.0  \n",
       "\n",
       "[867 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "AwdvVXT7tx4l",
    "outputId": "968031e8-48c2-4c44-f9aa-5210d8e0757e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Sarcastic Tweets: 0.25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print the pertcentage of sarcastic tweet in the dataset \n",
    "print(f'Percentage of Sarcastic Tweets: {np.round(df.sarcastic.mean(), 2)}')\n",
    "\n",
    "# calculate tweet lengths\n",
    "df['length'] = [len(str(t).split()) for t in df.tweet.values]\n",
    "\n",
    "# plot length distribution\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "sns.histplot(x='length', hue='sarcastic', data=df)\n",
    "plt.axvline(df[df.sarcastic==1].length.median(), c='orange', linestyle='--', label='Median (sarcastic)')\n",
    "plt.axvline(df[df.sarcastic==0].length.median(), linestyle='--', label='Median (not sarcastic)')\n",
    "plt.legend()\n",
    "plt.title('Lenght of tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rmm-npDJ1-2"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "Before the modelling phase, we perform some pre-processing tasks.\n",
    "\n",
    "First, since we are dealing with tweets, we eliminate hashtags and segment the words within the hashtag because most of the time they are constructed of multiple words.\n",
    "\n",
    "Using the library TextBlob we check and correct the spelling of the tweets. Tweets are usually quickly written texts and can contain many spelling mistakes that could mislead the model.\n",
    "\n",
    "Later, we substitute the contracted forms with their full form. Examples are verbs such as isn’t that is transformed to is not and can’t to can not. We then eliminate punctuation, links, emails and emojis.\n",
    "\n",
    "BERT expects input data in a specific format, with special tokens so we add [CLS] to mark the beginning and [SEP] at the separation/end of sentences. Furthermore, we tokenize our text into tokens that correspond to BERT’s vocabulary.\n",
    "\n",
    "After the tokenization, we assign to each token a sequence of integers that maps each input token to its index number in the BERT tokenizer vocabulary. Moreover, BERT requires that each input sentence is the same length, so we decide to set the maximum length of our inputs to 40 since we have seen in the distribution graph that most of the tweets are shorter or equal to 40.\n",
    "We apply the pad function that shortens or lengthens the sentence in order to reach the set maximum length. \n",
    "\n",
    "We define the attention mask that we will use in BERT and in the end we split the dataset into train, validation and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wmvDgbwTcOo",
    "outputId": "e56c1930-bc11-4046-d275-066a590df46d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word statistics files not found!\n",
      "Downloading... done!\n",
      "Unpacking... done!\n",
      "Reading twitter - 1grams ...\n",
      "generating cache file for faster loading...\n",
      "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
      "Reading twitter - 2grams ...\n",
      "generating cache file for faster loading...\n",
      "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "# splitting hashtags\n",
    "seg_tw = Segmenter(corpus=\"twitter\")\n",
    "collection = []\n",
    "\n",
    "def segmentation(word):\n",
    "  if \"#\" in word:\n",
    "    word=word.replace('#','')\n",
    "    word=seg_tw.segment(word)\n",
    "  elif \"@\" in word:\n",
    "    word=word.replace('@','')\n",
    "    word=seg_tw.segment(word)\n",
    "  return word\n",
    "\n",
    "for tweet in df.tweet:\n",
    "  segmented_words= [segmentation(word) for word in tweet.split()]\n",
    "  segmented_text = ' '.join(segmented_words)\n",
    "  collection.append(segmented_text)\n",
    "\n",
    "df.loc[:,\"tweet\"] = collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAAgh5KuLzIO",
    "outputId": "72363b5d-e411-4cac-be8e-434d93f2cdb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    }
   ],
   "source": [
    "# correct spelling mistakes\n",
    "new_text = df.loc[:,\"tweet\"].copy()\n",
    "collection=[]\n",
    "for text in new_text: \n",
    "  textBlb = TextBlob(text)          \n",
    "  textCorrected = textBlb.correct() \n",
    "  collection.append(textCorrected) \n",
    "\n",
    " \n",
    "df.loc[:,\"tweet\"] = collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmSNz2knDlvl"
   },
   "outputs": [],
   "source": [
    "# eliminate contractions\n",
    "collection = []   \n",
    "for tweet in df.tweet:\n",
    "  expanded_words= [contractions.fix(word) for word in tweet.split()]\n",
    "  expanded_text = ' '.join(expanded_words)\n",
    "  collection.append(expanded_text)\n",
    "\n",
    "df.loc[:,\"tweet\"] = collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSj5gG4RPpEy"
   },
   "outputs": [],
   "source": [
    "# eliminate punctiation\n",
    "string.punctuation\n",
    "for tweet in df.tweet:\n",
    "  punctuationfree=\"\".join([i for i in tweet if i not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vufvhuzVYv41"
   },
   "outputs": [],
   "source": [
    "# eliminate emailadresses, emojis, ...\n",
    "collection = [] \n",
    "new_text = df.loc[:,\"tweet\"].copy()\n",
    "for text in new_text: \n",
    "  #replace email addresses with \"emailaddress\"\n",
    "    text = text.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress')\n",
    "\n",
    "  #replace web addresses with \"webaddress\"\n",
    "    text = text.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
    "\n",
    "    pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    text = pattern.sub('', text)\n",
    "    text = \" \".join(filter(lambda x:x[0]!='@', text.split()))\n",
    "    #eliminate emojis\n",
    "    emoji = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001FFFF\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    text = emoji.sub(r'', text)\n",
    "    #eliminate all symbols \n",
    "    text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "    collection.append(text)\n",
    "\n",
    "df.loc[:,\"tweet\"] = collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6u6KlI_hAAE",
    "outputId": "cfe7eb98-ee8a-45d2-d818-b48775cdfa53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  sarcastic  length\n",
      "0  [CLS] The only thing I got from college is a c...          1      11\n",
      "1  [CLS] I love it when professors draw a big que...          1      26\n",
      "2  [CLS] Remember the hundred email from companie...          1      36\n",
      "3  [CLS] Today my poppop told me I was not “force...          1      17\n",
      "4  [CLS] orphan carl little witty mystical manage...          1      29\n"
     ]
    }
   ],
   "source": [
    "# adding tokens required by bert \n",
    "collection=[]\n",
    "\n",
    "new_text = df.loc[:,\"tweet\"].copy()\n",
    "for text in new_text:\n",
    "  text = \"[CLS] \" + text + \" [SEP]\"\n",
    "  collection.append(text)\n",
    "\n",
    "df.loc[:,\"tweet\"] = collection\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2O7On5PWL_Z",
    "outputId": "6767cd9c-f3ae-49b3-e4a6-2db08728c493"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "100%|██████████| 213450/213450 [00:00<00:00, 22051631.54B/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "sentences = df.tweet.values\n",
    "labels = df.sarcastic.values\n",
    "\n",
    "# tokenize the tweets using tokenizer from Bert using the bert-large-cased pre-trained model \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvJLdCMWWoec"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 40\n",
    "#padding the sentences to make them the same length \n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9EhseGyWtTh"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3H6Wi-hbW2Tr"
   },
   "outputs": [],
   "source": [
    "# split train, validation and test sets\n",
    "train_val_inputs, test_inputs, train_val_labels, test_labels = train_test_split(input_ids, labels, train_size = 0.8, random_state=42, shuffle=True) \n",
    "train_val_masks, test_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=42, shuffle=True, train_size=0.8)\n",
    "\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_val_inputs, train_val_labels, \n",
    "                                                                                    train_size = 0.9, random_state=42, shuffle=True) \n",
    "train_masks, validation_masks, _, _ = train_test_split(train_val_masks, train_val_inputs,\n",
    "                                             random_state=42, shuffle=True, train_size=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTYNsZdKTUGE"
   },
   "source": [
    "## Baseline models\n",
    "\n",
    "In the following we will test 4 baslines. 3 of those (Logsitic Regression, SVM and Random Forest) are general classifiers. These should give us an orientation on what is possible with the data without using any spcialized methods. The fourth model is an LSTM. With that, we try a model that is more suited for the task of dealing with sequences in particular. Though, it is still much smaller in terms of parameters than BERT or variants of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd0HOG_HT3_5"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mrs-sHNjTjIE",
    "outputId": "fe993145-00d2-4b15-e689-6d6fa1c65a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1: \tTrain:0.4340\tValidation:0.4260\n",
      "Logistic Regression Acc: \tTrain:0.7610\tValidation:0.7410\n",
      "\n",
      "#times model predicts sarcasm in validation set: 0\n"
     ]
    }
   ],
   "source": [
    "# define grid search parameters \n",
    "logreg_params = {\n",
    "    'C': [0.5, 1, 5, 10, 100, 500],\n",
    "}\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf_grid_logreg = GridSearchCV(estimator=clf, param_grid=logreg_params, cv = 5, n_jobs=-1)\n",
    "clf_grid_logreg.fit(train_inputs, train_labels) \n",
    "\n",
    "# check the f1 score\n",
    "train_pred = clf_grid_logreg.predict(train_inputs)\n",
    "val_pred = clf_grid_logreg.predict(validation_inputs)\n",
    "\n",
    "f1_train = np.round(f1_score(train_labels, train_pred,average = 'macro'), 3)\n",
    "f1_val = np.round(f1_score(validation_labels, val_pred,average = 'macro'), 3)\n",
    "\n",
    "acc_train = np.round(accuracy_score(train_labels, train_pred), 3)\n",
    "acc_val = np.round(accuracy_score(validation_labels, val_pred), 3)\n",
    "\n",
    "# append results\n",
    "\n",
    "print(f\"Logistic Regression F1: \\tTrain:{f1_train:.4f}\\tValidation:{f1_val:.4f}\")\n",
    "print(f\"Logistic Regression Acc: \\tTrain:{acc_train:.4f}\\tValidation:{acc_val:.4f}\")\n",
    "print()\n",
    "print(f\"#times model predicts sarcasm in validation set: {val_pred.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmAHfDmwUBkA"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VwLn_kzT9s_",
    "outputId": "bdf5e200-0383-42df-ed58-078cb39bbc7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1: \tTrain:0.4340\tValidation:0.4260\n",
      "SVM Acc: \tTrain:0.7610\tValidation:0.7410\n",
      "\n",
      "#times model predicts sarcasm in validation set: 0\n"
     ]
    }
   ],
   "source": [
    "#train the svc\n",
    "svc_params = {\n",
    "    'C': (0.1, 1., 10),\n",
    "}\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf_grid_svc = GridSearchCV(clf, svc_params, cv = 5, n_jobs= -1)\n",
    "clf_grid_svc.fit(train_inputs, train_labels)\n",
    "\n",
    "# check the f1 score\n",
    "train_pred = clf_grid_svc.predict(train_inputs)\n",
    "val_pred = clf_grid_svc.predict(validation_inputs)\n",
    "\n",
    "acc_train = np.round(accuracy_score(train_labels, train_pred), 3)\n",
    "acc_val = np.round(accuracy_score(validation_labels, val_pred), 3)\n",
    "\n",
    "# append results\n",
    "\n",
    "print(f\"SVM F1: \\tTrain:{f1_train:.4f}\\tValidation:{f1_val:.4f}\")\n",
    "print(f\"SVM Acc: \\tTrain:{acc_train:.4f}\\tValidation:{acc_val:.4f}\")\n",
    "print()\n",
    "print(f\"#times model predicts sarcasm in validation set: {val_pred.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQZ7oWLeUGg-"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2dG5rPsUKWy",
    "outputId": "e5fb8aa3-6a14-40b0-acff-0946bfa200a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1: \tTrain:0.4340\tValidation:0.4260\n",
      "Random Forest Acc: \tTrain:0.9980\tValidation:0.7370\n",
      "\n",
      "#times model predicts sarcasm in validation set: 1\n"
     ]
    }
   ],
   "source": [
    "# we start with a grid search on a RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "forest_params = {\n",
    "    'n_estimators': (50, 100),\n",
    "    'max_depth': [50, 100]\n",
    "}\n",
    "\n",
    "# perform gridsearch\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf_grid_forest = GridSearchCV(clf, forest_params, verbose=0, n_jobs=-1)\n",
    "clf_grid_forest.fit(train_inputs, train_labels)\n",
    "\n",
    "# check the f1 score\n",
    "train_pred = clf_grid_forest.predict(train_inputs)\n",
    "val_pred = clf_grid_forest.predict(validation_inputs)\n",
    "\n",
    "acc_train = np.round(accuracy_score(train_labels, train_pred), 3)\n",
    "acc_val = np.round(accuracy_score(validation_labels, val_pred), 3)\n",
    "\n",
    "# append results\n",
    "\n",
    "print(f\"Random Forest F1: \\tTrain:{f1_train:.4f}\\tValidation:{f1_val:.4f}\")\n",
    "print(f\"Random Forest Acc: \\tTrain:{acc_train:.4f}\\tValidation:{acc_val:.4f}\")\n",
    "print()\n",
    "print(f\"#times model predicts sarcasm in validation set: {val_pred.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEKf36bDcoej"
   },
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8NURjC8cofA"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olmjlfmvcofB"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3nRz9rjTr-s",
    "outputId": "fdbb4b89-7b4d-4003-d0cc-f4094b97bc41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss: \t0.5686, train accuracy:\t 75.59%\n",
      "Val loss: \t0.5913, val accuracy:\t 74.1%\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss: \t0.5524, train accuracy:\t 76.11%\n",
      "Val loss: \t0.8, val accuracy:\t 74.1%\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss: \t0.5527, train accuracy:\t 76.11%\n",
      "Val loss: \t0.3478, val accuracy:\t 74.1%\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss: \t0.5527, train accuracy:\t 76.11%\n",
      "Val loss: \t0.4147, val accuracy:\t 74.1%\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss: \t0.5506, train accuracy:\t 76.11%\n",
      "Val loss: \t0.5063, val accuracy:\t 74.1%\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss: \t0.5533, train accuracy:\t 76.11%\n",
      "Val loss: \t0.5066, val accuracy:\t 74.1%\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss: \t0.5496, train accuracy:\t 76.11%\n",
      "Val loss: \t0.3254, val accuracy:\t 74.1%\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss: \t0.5495, train accuracy:\t 76.07%\n",
      "Val loss: \t0.6023, val accuracy:\t 74.1%\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss: \t0.5516, train accuracy:\t 76.11%\n",
      "Val loss: \t0.6585, val accuracy:\t 74.1%\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss: \t0.55, train accuracy:\t 76.11%\n",
      "Val loss: \t0.3757, val accuracy:\t 74.1%\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Hyper-parameters \n",
    "\n",
    "num_epochs = 10\n",
    "hidden_size = 256\n",
    "num_layers = 4\n",
    "\n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, self.hidden_size).to(device) \n",
    "      \n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = self.linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = LSTM(MAX_LEN, hidden_size, num_layers).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())  \n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    losses = []\n",
    "\n",
    "    for i, (input_ids, att, labels) in enumerate(train_dataloader):  \n",
    "        \n",
    "        input = input_ids.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input)\n",
    "        loss = loss_fn(outputs.view(labels.shape), labels)\n",
    "               \n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        preds = (outputs>0.5).float()\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (preds.view(labels.size()) == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Train loss: \\t{np.round(np.mean(losses), 4)}, train accuracy:\\t {np.round(acc, 2)}%')\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        losses = []\n",
    "\n",
    "        for (input_ids, att, labels) in validation_dataloader:  \n",
    "        \n",
    "            input = input_ids.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input)\n",
    "            # max returns (value ,index)\n",
    "            losses.append(loss.item())\n",
    "            preds = (outputs>0.5).float()\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (preds.view(labels.size()) == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Val loss: \\t{np.round(np.mean(losses), 4)}, val accuracy:\\t {np.round(acc, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnBHGNfQkJst"
   },
   "source": [
    "**Evaluation of the Baselines**  \n",
    "\n",
    "\n",
    "\n",
    "| Model      | Train accuracy | Validation accuracy|\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Logistic Regression | 76.1%| 74.1% |\n",
    "| SVM   | 76.1%| 74.1% |\n",
    "| Random Forest   | 99.8% | 73.7% |\n",
    "| LSTM   | 76.1% | 74.1%|\n",
    "\n",
    "All of our baselines achive an accuracy of 74.1% on the validation set. This corresponds to the number of non-sarcastic Tweets in our dataset. Checking our predictions it becomes apparent than the models do not predicts any sarcasm on the validation set (only random forest once and it was wrong). This is not too surprising as all models do not learn on the training set (except for RandomForest which manages to learn the training data, but not generalizes to the validation).\n",
    "\n",
    "From those baselines it becomes clear that detecting sarcasm is not an easy task. Maybe BERT can perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "in6GkEbLUMLh"
   },
   "source": [
    "## BERT and variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E7QAYsvc30V"
   },
   "source": [
    "### BERT for Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l9bRQRFVfHK"
   },
   "source": [
    "BERT for sequence classification is a variation of the classic BERT algorithm tailored for classification tasks. This variant consists of Bert Model transformer with a sequence classification/regression head on top. The BERT for sequence classificiation belongs to PyTorch torch.nn.Module sub-class and we can handle it as a regular PyTorch Modul. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn8GzVOdvlIn"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgDSxqbgXvUT"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwpsxRL8XagR",
    "outputId": "960a8daf-39ea-4238-d07c-74b1598a01dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242874899/1242874899 [00:56<00:00, 21884944.87B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-large-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFmY3UnoX2p2"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhPVE_xuT2Jd",
    "outputId": "bd12b0b7-fcc2-4bb2-f54a-b3abc58c27ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=2e-5,\n",
    "                     warmup=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZlsgJ5IRywR"
   },
   "outputs": [],
   "source": [
    "#function that flatten input tensors and calculate accuracy \n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qgu9L47MU6KO"
   },
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "\n",
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  optimizer, \n",
    "  device\n",
    "):\n",
    "      model.train()\n",
    "  \n",
    "    # Tracking variables\n",
    "      tr_loss,tr_accuracy = 0,0,\n",
    "      nb_tr_steps = 0\n",
    "\n",
    "      for step, batch in enumerate(data_loader):\n",
    "    # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n",
    "    # Backward pass\n",
    "        loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Update tracking variables\n",
    "       # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_tr_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        return tr_loss/nb_tr_steps, tr_accuracy/nb_tr_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukeA2gIuKOgs"
   },
   "outputs": [],
   "source": [
    "def val_model(model, data_loader, device):\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables \n",
    "  val_loss, val_accuracy = 0, 0\n",
    "  nb_val_steps = 0\n",
    "      \n",
    "  # Evaluate data for one epoch\n",
    "  for batch in data_loader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    # Update tracking variables\n",
    "    val_loss += loss.item()\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_val_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    val_accuracy += tmp_val_accuracy\n",
    "    nb_val_steps += 1\n",
    "\n",
    "    return val_loss/nb_val_steps, val_accuracy/nb_val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVGi-0MjVKHx",
    "outputId": "d02b52a9-b8c6-408b-909f-3e638eb04361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.7441381216049194 accuracy 0.4375\n",
      "Val loss 0.6117755770683289 accuracy 0.8125\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "Train loss 0.6035366058349609 accuracy 0.8125\n",
      "Val loss 0.5348394513130188 accuracy 0.8125\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "Train loss 0.5155854821205139 accuracy 0.875\n",
      "Val loss 0.5369176268577576 accuracy 0.75\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "Train loss 0.7410274147987366 accuracy 0.5625\n",
      "Val loss 0.5542116761207581 accuracy 0.75\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "Train loss 0.5871286988258362 accuracy 0.75\n",
      "Val loss 0.593521773815155 accuracy 0.75\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "Train loss 0.5864025354385376 accuracy 0.75\n",
      "Val loss 0.6475628018379211 accuracy 0.6875\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "Train loss 0.8850043416023254 accuracy 0.4375\n",
      "Val loss 0.6751300692558289 accuracy 0.75\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "Train loss 0.7738711833953857 accuracy 0.75\n",
      "Val loss 0.5878969430923462 accuracy 0.75\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "Train loss 0.5733192563056946 accuracy 0.6875\n",
      "Val loss 0.6107786297798157 accuracy 0.75\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "Train loss 0.5737895965576172 accuracy 0.75\n",
      "Val loss 0.5934000611305237 accuracy 0.75\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "Train loss 0.6033180356025696 accuracy 0.75\n",
      "Val loss 0.5620133876800537 accuracy 0.75\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "Train loss 0.42216956615448 accuracy 0.875\n",
      "Val loss 0.5634366869926453 accuracy 0.75\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "Train loss 0.5510116219520569 accuracy 0.75\n",
      "Val loss 0.5887311100959778 accuracy 0.75\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "Train loss 0.9050058722496033 accuracy 0.5625\n",
      "Val loss 0.529740035533905 accuracy 0.75\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "Train loss 0.45715636014938354 accuracy 0.875\n",
      "Val loss 0.5634345412254333 accuracy 0.75\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "Train loss 0.6403976082801819 accuracy 0.75\n",
      "Val loss 0.5637691617012024 accuracy 0.75\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "Train loss 0.4349467158317566 accuracy 0.875\n",
      "Val loss 0.5624893307685852 accuracy 0.75\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "Train loss 0.6825785040855408 accuracy 0.6875\n",
      "Val loss 0.5620277523994446 accuracy 0.75\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "Train loss 0.6055319309234619 accuracy 0.75\n",
      "Val loss 0.5648074746131897 accuracy 0.75\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "Train loss 0.4893258213996887 accuracy 0.8125\n",
      "Val loss 0.5619906187057495 accuracy 0.75\n",
      "\n",
      "CPU times: user 13.3 s, sys: 6.71 s, total: 20 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS=20\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_loss, train_acc = train_epoch(\n",
    "    model,\n",
    "    train_dataloader,    \n",
    "    optimizer, \n",
    "    device\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_loss, val_acc = val_model(\n",
    "    model,\n",
    "    validation_dataloader,\n",
    "    device\n",
    "  )\n",
    "\n",
    "  print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    # torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Y0apYKBkb5z"
   },
   "outputs": [],
   "source": [
    "acc = [h for h in history['train_acc']]\n",
    "val_acc = [h for h in history['val_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "m5dSVC3_kyE8",
    "outputId": "d8071902-064c-445e-82e8-0225d6a7f24e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc, label='train accuracy')\n",
    "plt.plot(val_acc, label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wgFDORodDEo"
   },
   "source": [
    "### BERTweet\n",
    "\n",
    "As the standard BERT for Sequence Classification does not manage to make useful predictions on the validation set, we try a different version. For that, we get BERTweet from the Huggingface page. \n",
    "\n",
    "\n",
    "> BERTweet is the first public large-scale language model pre-trained for English Tweets. BERTweet is trained based on the RoBERTa pre-training procedure. The corpus used to pre-train BERTweet consists of 850M English Tweets (16B word tokens ~ 80GB), containing 845M Tweets streamed from 01/2012 to 08/2019 and 5M Tweets related to the COVID-19 pandemic. The general architecture and experimental results of BERTweet can be found in our [paper](https://aclanthology.org/2020.emnlp-demos.2/).\n",
    "\n",
    "As out data are sarcastic Tweets, we hope that this model might be able to better capture their characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjS2316-eLX3"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYII3nKqRMJm"
   },
   "outputs": [],
   "source": [
    "class SarcasticBERTweet(nn.Module):\n",
    "  \n",
    "  def __init__(self, n_hidden):\n",
    "    super().__init__()\n",
    "    self.n_hidden = n_hidden\n",
    "\n",
    "    self.bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "    self.drop1 = nn.Dropout(p=0.2)\n",
    "    self.linear1 = nn.Linear(self.bert.config.hidden_size, self.n_hidden)\n",
    "    self.sigmoid1 = nn.Sigmoid()\n",
    "    # self.drop2 = nn.Dropout(p=0.3)\n",
    "    self.linear2 = nn.Linear(self.n_hidden, 1)\n",
    "    self.sigmoid2 = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    output = self.bert(\n",
    "      input_ids=input_ids, \n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    out = self.drop1(output['pooler_output'])\n",
    "    out = self.linear1(out)\n",
    "    out = self.sigmoid1(out)\n",
    "    # out = self.drop2(out)\n",
    "    out = self.linear2(out)\n",
    "    out = self.sigmoid2(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0bbdf30ebf3b41f4852b0ef05c5fdc0c",
      "ebb458160c64429ab0b3d9076a9321a0",
      "6875b0c1fb624dd28d5ac1ad624455f7",
      "3fa29e38267043f3ba3ac94b7c7f6fc3",
      "8b013beaf91b401787609f4ce0286811",
      "d384cae2a98043f1b3d812b0f0917fcb",
      "8174e26919a442fabf9f043f915daab4",
      "d79fe1f2b82b416787c2688aaea794cc",
      "19e0484dcf934b0591f527677762f469",
      "5b52953eb63d45bf854ff0930e1fbccd",
      "59de705ea1f44b209513027282da275b",
      "e55d2f1fd4cb461f8e3ef4bf3560581c",
      "1fe6f35cebc443c1b29cce51ad61940a",
      "9f148c9fcb2e44ec978fc3f2c2894531",
      "731b19d592584aa9b8061de9424ad7dd",
      "03b35a8c63644fec892d385038deafcb",
      "ff7c7df658374cb2a8a8156ca40a50c5",
      "404e09a8311f4e89bec02e2d8d6d1117",
      "9c468461d441458183267731fb07062e",
      "9f39a3764d5c49f9afdd67fc46103e55",
      "2c2ed58534294ae481489d933023a8c0",
      "062c6b2e13554c0a9cc8f98baa1a4201"
     ]
    },
    "id": "-mm-4gYQRMJt",
    "outputId": "013b7d32-cbe7-4538-cc83-290e79f1cb25"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbdf30ebf3b41f4852b0ef05c5fdc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55d2f1fd4cb461f8e3ef4bf3560581c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/517M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SarcasticBERTweet(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop1): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (sigmoid1): Sigmoid()\n",
       "  (linear2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SarcasticBERTweet(256)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_JV-GUr_xWT"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_sfQrLG_zF7"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "# define loss, optimizer, and scheduler\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XogUr2jL__27"
   },
   "outputs": [],
   "source": [
    "# define train run\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples, threshold=0.5):\n",
    "  # set training modes\n",
    "  model = model.train()\n",
    "\n",
    "  # initiate tracking variables\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  # loop over data\n",
    "  for (input_ids, attention_mask, labels) in data_loader:\n",
    "     \n",
    "    # send inputs to GPU\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    targets = labels.float().to(device)\n",
    "\n",
    "    # aplly model\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    outputs = outputs.flatten()\n",
    "\n",
    "    # make predictions and calculate the loss\n",
    "    preds = (outputs>threshold).float()\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzhlrQWqDa1a"
   },
   "outputs": [],
   "source": [
    "# define evaluation run\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples, threshold=0.5):\n",
    "  # set evaluation mode\n",
    "  model = model.eval()\n",
    "\n",
    "  # initiate tracking variables\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  # loop over validation data\n",
    "  with torch.no_grad():\n",
    "    for (input_ids, attention_mask, labels) in data_loader:\n",
    "      \n",
    "      # send inputs to GPU\n",
    "      input_ids = input_ids.to(device)\n",
    "      attention_mask = attention_mask.to(device)\n",
    "      targets = labels.float().to(device)\n",
    "      \n",
    "      # apply model\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      outputs = outputs.flatten()\n",
    "\n",
    "      # make predictions and calculate the loss\n",
    "      preds = (outputs>threshold).float()\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PN1H6_hoDxoH",
    "outputId": "816787e5-40ab-4d71-a156-c38a81d9e4d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.5788145896333915 accuracy 0.7354709418837675\n",
      "Val   loss 0.5737423449754715 accuracy 0.7410071942446044\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.5532918688960564 accuracy 0.7611222444889779\n",
      "Val   loss 0.5684511429733701 accuracy 0.7410071942446044\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.551880575907536 accuracy 0.7611222444889779\n",
      "Val   loss 0.5742726392216153 accuracy 0.7410071942446044\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.5507516836126646 accuracy 0.7611222444889779\n",
      "Val   loss 0.5706530312697092 accuracy 0.7410071942446044\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.5479435376249827 accuracy 0.7611222444889779\n",
      "Val   loss 0.5763416066765785 accuracy 0.7410071942446044\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.5440523861310421 accuracy 0.7611222444889779\n",
      "Val   loss 0.5669677919811673 accuracy 0.7410071942446044\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.4956569917117938 accuracy 0.7727454909819639\n",
      "Val   loss 0.6210456738869349 accuracy 0.6690647482014389\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.4457478577700945 accuracy 0.8244488977955912\n",
      "Val   loss 0.7484471268124051 accuracy 0.5575539568345323\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.38959599840335357 accuracy 0.8545090180360722\n",
      "Val   loss 0.6072933930489752 accuracy 0.723021582733813\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.34784965589642525 accuracy 0.8853707414829659\n",
      "Val   loss 0.6840994440846973 accuracy 0.6618705035971223\n",
      "\n",
      "CPU times: user 3min 3s, sys: 1min 3s, total: 4min 6s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the model\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  # call train run\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_dataloader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(train_data)\n",
    "  )\n",
    "\n",
    "  # report loss and accuracy\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  # call eval run\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    validation_dataloader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(validation_data)\n",
    "  )\n",
    "\n",
    "  # report loss and accuracy\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  # update history\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  # save best model\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TIjFhB-Pk0x"
   },
   "outputs": [],
   "source": [
    "acc = [h.cpu().numpy() for h in history['train_acc']]\n",
    "val_acc = [h.cpu().numpy() for h in history['val_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "cmUJaFFMHR5y",
    "outputId": "05c659f5-404a-4e14-928f-ab0064bda98d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc, label='train accuracy')\n",
    "plt.plot(val_acc, label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-WqnSaWpQQg"
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "siZ5yTeRqax6",
    "outputId": "f480c111-952b-405c-df48-15d22a49837c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model achieved 64.55% accuracy on the test set. A naive predictor that would only predict non-sarcastic would achieve: 71.33%.\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_dataloader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(test_data)\n",
    "  )\n",
    "\n",
    "print(f'The model achieved {np.round(test_acc.cpu()*100, 2)}% accuracy on the test set. A naive predictor that would only predict non-sarcastic would achieve: {np.round(100*(1-test_labels.sum()/len(test_labels)).numpy(), 2)}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lu0lVLsTsK8h"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The task was to classify Tweets as sarcastic or non-sarcastic. We tried several baseline models and two versions of BERT. We tested the second one (BERTweet, fine-tuned on english Tweets) on our test set:\n",
    "\n",
    "|Model|Test accuracy|\n",
    "|--|--|\n",
    "|Naive Classifier (all 0)|71.33%|\n",
    "|BERTweet|64.55%|\n",
    "\n",
    "None of our models was able to make any meaningful predictions in the validation or test set. Mainly our classifiers predicted all the samples to be non-sarcastic. This means they were not able to learn any useful features from the training data that would make it possible to identify sarcastic Tweets. \n",
    "\n",
    "To test if there is something wrong with our models, we applied them to another dataset with a simpler classification task. There, the task consisted of identifying tweets related to catastrophe ([source](https://www.kaggle.com/competitions/nlp-getting-started)). For this task, the same two BERT models managed to learn the pattern and performed well. \n",
    "\n",
    "In the end, we can conclude that the models we implemented are not able to properly learn how to solve the task of sarcastic classification. We might be able to improve our modeling if we had more training data or we could implement a model that is more based on theory and understanding of the tasks’ features. An example of this can be found in Shani et al, 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeaJn2BBtipo"
   },
   "source": [
    "\n",
    "\n",
    "<center>\n",
    "<i><b>Fin</b></i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz214PCUnPhq"
   },
   "source": [
    "# References\n",
    "\n",
    "* Chen Shani, Nadav Borenstein, and Dafna Shahaf. \"How Did This Get Funded?! Automatically Identifying Quirky Scientific Achievements\". Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (2021)\n",
    "\n",
    "* Mao, Jihang and Wanli Liu. “A BERT-based Approach for Automatic Humor Detection and Scoring.” IberLEF@SEPLN (2019)\n",
    "\n",
    "* Annamoradnejad, Issa. “ColBERT: Using BERT Sentence Embedding for Humor Detection.” ArXiv abs/2004.12765 (2020): n. pag.\n",
    "\n",
    "* https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03\n",
    "\n",
    "* Dat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen. 2020. BERTweet: A pre-trained language model for English Tweets. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 9–14, Online. Association for Computational Linguistics."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03b35a8c63644fec892d385038deafcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "062c6b2e13554c0a9cc8f98baa1a4201": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bbdf30ebf3b41f4852b0ef05c5fdc0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebb458160c64429ab0b3d9076a9321a0",
       "IPY_MODEL_6875b0c1fb624dd28d5ac1ad624455f7",
       "IPY_MODEL_3fa29e38267043f3ba3ac94b7c7f6fc3"
      ],
      "layout": "IPY_MODEL_8b013beaf91b401787609f4ce0286811"
     }
    },
    "19e0484dcf934b0591f527677762f469": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1fe6f35cebc443c1b29cce51ad61940a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff7c7df658374cb2a8a8156ca40a50c5",
      "placeholder": "​",
      "style": "IPY_MODEL_404e09a8311f4e89bec02e2d8d6d1117",
      "value": "Downloading: 100%"
     }
    },
    "2c2ed58534294ae481489d933023a8c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fa29e38267043f3ba3ac94b7c7f6fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b52953eb63d45bf854ff0930e1fbccd",
      "placeholder": "​",
      "style": "IPY_MODEL_59de705ea1f44b209513027282da275b",
      "value": " 558/558 [00:00&lt;00:00, 16.8kB/s]"
     }
    },
    "404e09a8311f4e89bec02e2d8d6d1117": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59de705ea1f44b209513027282da275b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b52953eb63d45bf854ff0930e1fbccd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6875b0c1fb624dd28d5ac1ad624455f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d79fe1f2b82b416787c2688aaea794cc",
      "max": 558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_19e0484dcf934b0591f527677762f469",
      "value": 558
     }
    },
    "731b19d592584aa9b8061de9424ad7dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c2ed58534294ae481489d933023a8c0",
      "placeholder": "​",
      "style": "IPY_MODEL_062c6b2e13554c0a9cc8f98baa1a4201",
      "value": " 517M/517M [00:09&lt;00:00, 61.3MB/s]"
     }
    },
    "8174e26919a442fabf9f043f915daab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b013beaf91b401787609f4ce0286811": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c468461d441458183267731fb07062e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f148c9fcb2e44ec978fc3f2c2894531": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c468461d441458183267731fb07062e",
      "max": 542529064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f39a3764d5c49f9afdd67fc46103e55",
      "value": 542529064
     }
    },
    "9f39a3764d5c49f9afdd67fc46103e55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d384cae2a98043f1b3d812b0f0917fcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d79fe1f2b82b416787c2688aaea794cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e55d2f1fd4cb461f8e3ef4bf3560581c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1fe6f35cebc443c1b29cce51ad61940a",
       "IPY_MODEL_9f148c9fcb2e44ec978fc3f2c2894531",
       "IPY_MODEL_731b19d592584aa9b8061de9424ad7dd"
      ],
      "layout": "IPY_MODEL_03b35a8c63644fec892d385038deafcb"
     }
    },
    "ebb458160c64429ab0b3d9076a9321a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d384cae2a98043f1b3d812b0f0917fcb",
      "placeholder": "​",
      "style": "IPY_MODEL_8174e26919a442fabf9f043f915daab4",
      "value": "Downloading: 100%"
     }
    },
    "ff7c7df658374cb2a8a8156ca40a50c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
